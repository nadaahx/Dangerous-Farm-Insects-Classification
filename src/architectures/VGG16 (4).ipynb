{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxHM8ae50iY_",
        "outputId": "c604c7f7-c851-4be1-f6c2-e696b5d629a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "iHYZU2Fgb08f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir = \"/content/drive/MyDrive/farm_insects_project/data/processed/farm_insects\"\n",
        "\n",
        "\n",
        "train_dir = f\"{data_dir}/splits/train\"\n",
        "val_dir = f\"{data_dir}/splits/val\"\n",
        "test_dir = f\"{data_dir}/splits/test\"\n"
      ],
      "metadata": {
        "id": "0j7bKv53z76o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
        "test_dataset  = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "print(\"Number of training images:\", len(train_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_t-iFI_z_LL",
        "outputId": "8e8d13d3-78c0-45e0-f9d8-11ecafb77f72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Africanized Honey Bees (Killer Bees)', 'Aphids', 'Armyworms', 'Brown Marmorated Stink Bugs', 'Cabbage Loopers', 'Citrus Canker', 'Colorado Potato Beetles', 'Corn Borers', 'Corn Earworms', 'Fall Armyworms', 'Fruit Flies', 'Spider Mites', 'Thrips', 'Tomato Hornworms', 'Western Corn Rootworms']\n",
            "Number of training images: 808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "vgg16.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "vgg16 = vgg16.to(device)\n",
        "print(\"Model modified for\", num_classes, \"classes\")\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg16.classifier[6].parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    vgg16.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "vgg16.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = vgg16(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(\"\\n Final Evaluation Metrics:\")\n",
        "print(f\"Overall Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Overall Precision: {precision:.4f}\")\n",
        "print(f\"Overall Recall:    {recall:.4f}\")\n",
        "print(f\"Overall F1-score:  {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icrb3ZY-zaEA",
        "outputId": "71bf1e38-d66e-4a1e-c8d3-9bc4b622f355"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Model modified for 15 classes\n",
            "Epoch [1/20] - Training Loss: 2.6994\n",
            "Epoch [2/20] - Training Loss: 2.2913\n",
            "Epoch [3/20] - Training Loss: 1.9945\n",
            "Epoch [4/20] - Training Loss: 1.7823\n",
            "Epoch [5/20] - Training Loss: 1.6334\n",
            "Epoch [6/20] - Training Loss: 1.5382\n",
            "Epoch [7/20] - Training Loss: 1.4377\n",
            "Epoch [8/20] - Training Loss: 1.3638\n",
            "Epoch [9/20] - Training Loss: 1.3291\n",
            "Epoch [10/20] - Training Loss: 1.2442\n",
            "Epoch [11/20] - Training Loss: 1.2022\n",
            "Epoch [12/20] - Training Loss: 1.1603\n",
            "Epoch [13/20] - Training Loss: 1.1372\n",
            "Epoch [14/20] - Training Loss: 1.1125\n",
            "Epoch [15/20] - Training Loss: 1.0665\n",
            "Epoch [16/20] - Training Loss: 1.0394\n",
            "Epoch [17/20] - Training Loss: 1.0159\n",
            "Epoch [18/20] - Training Loss: 0.9706\n",
            "Epoch [19/20] - Training Loss: 0.9920\n",
            "Epoch [20/20] - Training Loss: 0.9533\n",
            "\n",
            " Final Evaluation Metrics:\n",
            "Overall Accuracy:  0.6245\n",
            "Overall Precision: 0.6324\n",
            "Overall Recall:    0.6245\n",
            "Overall F1-score:  0.6158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "googlenet = models.googlenet(weights=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Freeze all layers first\n",
        "for param in googlenet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last Inception block and the final classifier\n",
        "for param in googlenet.inception5b.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "googlenet.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "googlenet = googlenet.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, googlenet.parameters()), lr=1e-4)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    googlenet.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = googlenet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "googlenet.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = googlenet(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(\"\\n Final Performance Metrics:\")\n",
        "print(f\"Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1 Score : {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYHU62fJoGLt",
        "outputId": "065a142a-c53e-48ac-f22b-831aee1663e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 136MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] - Training Loss: 2.6183\n",
            "Epoch [2/20] - Training Loss: 2.3058\n",
            "Epoch [3/20] - Training Loss: 2.0690\n",
            "Epoch [4/20] - Training Loss: 1.8761\n",
            "Epoch [5/20] - Training Loss: 1.7164\n",
            "Epoch [6/20] - Training Loss: 1.5816\n",
            "Epoch [7/20] - Training Loss: 1.4382\n",
            "Epoch [8/20] - Training Loss: 1.3409\n",
            "Epoch [9/20] - Training Loss: 1.2568\n",
            "Epoch [10/20] - Training Loss: 1.1882\n",
            "Epoch [11/20] - Training Loss: 1.1130\n",
            "Epoch [12/20] - Training Loss: 1.0404\n",
            "Epoch [13/20] - Training Loss: 1.0028\n",
            "Epoch [14/20] - Training Loss: 0.9657\n",
            "Epoch [15/20] - Training Loss: 0.8827\n",
            "Epoch [16/20] - Training Loss: 0.8468\n",
            "Epoch [17/20] - Training Loss: 0.7893\n",
            "Epoch [18/20] - Training Loss: 0.7631\n",
            "Epoch [19/20] - Training Loss: 0.7293\n",
            "Epoch [20/20] - Training Loss: 0.6817\n",
            "\n",
            " Final Performance Metrics:\n",
            "Accuracy : 0.6482\n",
            "Precision: 0.6577\n",
            "Recall   : 0.6482\n",
            "F1 Score : 0.6461\n"
          ]
        }
      ]
    }
  ]
}
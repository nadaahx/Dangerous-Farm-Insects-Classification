{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHYZU2Fgb08f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_t-iFI_z_LL",
        "outputId": "8e8d13d3-78c0-45e0-f9d8-11ecafb77f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['Africanized Honey Bees (Killer Bees)', 'Aphids', 'Armyworms', 'Brown Marmorated Stink Bugs', 'Cabbage Loopers', 'Citrus Canker', 'Colorado Potato Beetles', 'Corn Borers', 'Corn Earworms', 'Fall Armyworms', 'Fruit Flies', 'Spider Mites', 'Thrips', 'Tomato Hornworms', 'Western Corn Rootworms']\n",
            "Number of training images: 808\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
        "test_dataset  = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "print(\"Number of training images:\", len(train_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYHU62fJoGLt",
        "outputId": "065a142a-c53e-48ac-f22b-831aee1663e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 136MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20] - Training Loss: 2.6183\n",
            "Epoch [2/20] - Training Loss: 2.3058\n",
            "Epoch [3/20] - Training Loss: 2.0690\n",
            "Epoch [4/20] - Training Loss: 1.8761\n",
            "Epoch [5/20] - Training Loss: 1.7164\n",
            "Epoch [6/20] - Training Loss: 1.5816\n",
            "Epoch [7/20] - Training Loss: 1.4382\n",
            "Epoch [8/20] - Training Loss: 1.3409\n",
            "Epoch [9/20] - Training Loss: 1.2568\n",
            "Epoch [10/20] - Training Loss: 1.1882\n",
            "Epoch [11/20] - Training Loss: 1.1130\n",
            "Epoch [12/20] - Training Loss: 1.0404\n",
            "Epoch [13/20] - Training Loss: 1.0028\n",
            "Epoch [14/20] - Training Loss: 0.9657\n",
            "Epoch [15/20] - Training Loss: 0.8827\n",
            "Epoch [16/20] - Training Loss: 0.8468\n",
            "Epoch [17/20] - Training Loss: 0.7893\n",
            "Epoch [18/20] - Training Loss: 0.7631\n",
            "Epoch [19/20] - Training Loss: 0.7293\n",
            "Epoch [20/20] - Training Loss: 0.6817\n",
            "\n",
            " Final Performance Metrics:\n",
            "Accuracy : 0.6482\n",
            "Precision: 0.6577\n",
            "Recall   : 0.6482\n",
            "F1 Score : 0.6461\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "googlenet = models.googlenet(weights=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Freeze all layers first\n",
        "for param in googlenet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last Inception block and the final classifier\n",
        "for param in googlenet.inception5b.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "googlenet.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "googlenet = googlenet.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, googlenet.parameters()), lr=1e-4)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    googlenet.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = googlenet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "googlenet.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = googlenet(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(\"\\n Final Performance Metrics:\")\n",
        "print(f\"Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1 Score : {f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
